{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "In this lecture we fixed a number of parameters for the neural model, including:\n",
    "* the number of layers\n",
    "* the number of neurons per layer\n",
    "* the batch size\n",
    "* the number of epochs\n",
    "* the optimizer\n",
    "\n",
    "The choice of these parameters was pretty much randomean. There was no formal method we used to set these parameters. Perform a grid search (similar to the one we performed in our scikit-learn lectures) varying the range of these parameters within the following ranges/sets:\n",
    "\n",
    "* number of layers [low = 3, high = 5, step = 1]\n",
    "* number of neurons **per layer** [low = 32, high = 256, step = 32 ]\n",
    "* batch size [low = 1000, high = 10000, step = 1000]\n",
    "* number of epochs [low = 10, high = 30, step = 10]\n",
    "* optimizer {Adam, SGD, AdamW}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, AdamW\n",
    "import time\n",
    "\n",
    "# Load the Fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Smaller subset of the data for demonstration/time reasons \n",
    "train_images, train_labels = train_images[:10000], train_labels[:10000]\n",
    "test_images, test_labels   = test_images[:2000],   test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers=3, neurons=128, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Build and compile a Sequential model with:\n",
    "      - Flatten input,\n",
    "      - `num_layers` hidden Dense layers, each with `neurons` units, ReLU activation,\n",
    "      - Output layer with 10 units (softmax).\n",
    "      - `optimizer` one of ['adam', 'sgd', 'adamw'].\n",
    "\n",
    "    Returns compiled model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Create the optimizer\n",
    "    if optimizer.lower() == 'adam':\n",
    "        opt = Adam()\n",
    "    elif optimizer.lower() == 'sgd':\n",
    "        opt = SGD()\n",
    "    elif optimizer.lower() == 'adamw':\n",
    "        opt = AdamW()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer}\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc=0.8045 with {'num_layers': 3, 'neurons': 32, 'batch_size': 1000, 'epochs': 10, 'optimizer': 'adam'}\n",
      "New best acc=0.8395 with {'num_layers': 3, 'neurons': 32, 'batch_size': 1000, 'epochs': 20, 'optimizer': 'adam'}\n",
      "New best acc=0.8445 with {'num_layers': 3, 'neurons': 32, 'batch_size': 1000, 'epochs': 20, 'optimizer': 'adamw'}\n",
      "New best acc=0.8450 with {'num_layers': 3, 'neurons': 32, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adam'}\n",
      "New best acc=0.8545 with {'num_layers': 3, 'neurons': 32, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adamw'}\n",
      "New best acc=0.8585 with {'num_layers': 3, 'neurons': 64, 'batch_size': 1000, 'epochs': 20, 'optimizer': 'adamw'}\n",
      "New best acc=0.8590 with {'num_layers': 3, 'neurons': 96, 'batch_size': 1000, 'epochs': 20, 'optimizer': 'adam'}\n",
      "New best acc=0.8660 with {'num_layers': 3, 'neurons': 96, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adam'}\n",
      "New best acc=0.8730 with {'num_layers': 3, 'neurons': 160, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adamw'}\n",
      "New best acc=0.8790 with {'num_layers': 5, 'neurons': 256, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adamw'}\n",
      "\n",
      "Finished grid search in 2752.83 seconds.\n",
      "Best test accuracy: 0.8790000081062317\n",
      "Best parameters: {'num_layers': 5, 'neurons': 256, 'batch_size': 1000, 'epochs': 30, 'optimizer': 'adamw'}\n"
     ]
    }
   ],
   "source": [
    "num_layers_list = [3, 4, 5]\n",
    "neurons_list = range(32, 257, 32)      # 32 to 256 (step=32)\n",
    "batch_size_list = range(1000, 10001, 1000)  # 1000..10000 step=1000\n",
    "epochs_list = [10, 20, 30]\n",
    "optimizers_list = ['adam', 'sgd', 'adamw']\n",
    "\n",
    "\n",
    "best_acc = 0.0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for num_layers in num_layers_list:\n",
    "    for neurons in neurons_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            for epochs in epochs_list:\n",
    "                for optimizer_name in optimizers_list:\n",
    "                    \n",
    "                    # 1. Build the model\n",
    "                    model = build_model(\n",
    "                        num_layers=num_layers,\n",
    "                        neurons=neurons,\n",
    "                        optimizer=optimizer_name\n",
    "                    )\n",
    "                    \n",
    "                    # 2. Fit/Train\n",
    "                    history = model.fit(\n",
    "                        train_images, train_labels,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0  # no output\n",
    "                    )\n",
    "                    \n",
    "                    # 3. Evaluate on TEST set (but typically you'd do this on a validation set)\n",
    "                    loss, acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "                    \n",
    "                    # 4. Check if we got a better accuracy\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_params = {\n",
    "                            'num_layers': num_layers,\n",
    "                            'neurons': neurons,\n",
    "                            'batch_size': batch_size,\n",
    "                            'epochs': epochs,\n",
    "                            'optimizer': optimizer_name\n",
    "                        }\n",
    "                        \n",
    "                        # Print interim result (optional, helps track progress)\n",
    "                        print(f\"New best acc={acc:.4f} with {best_params}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nFinished grid search in {end_time - start_time:.2f} seconds.\")\n",
    "print(\"Best test accuracy:\", best_acc)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('CPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
